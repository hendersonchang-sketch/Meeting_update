#!/usr/bin/env python3
"""
TwitterHot AI Prompt æ¯æ—¥ ETL Pipeline (ä¿®æ­£ç‰ˆ)
åŠŸèƒ½ï¼šå¾ ttmouse.com API æŠ“å– AI promptsï¼Œä½¿ç”¨ Gemini API é€²è¡Œç¿»è­¯ã€æ¨™ç±¤æå–èˆ‡å‘é‡åµŒå…¥
"""

import os
import json
import sys
import time
import argparse
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any
import requests
import google.generativeai as genai


# ============ è¨­å®šå€ ============

# Google Gemini API é‡‘é‘°
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY", "")
if not GOOGLE_API_KEY:
    print("âš ï¸  è­¦å‘Šï¼šæœªè¨­å®š GOOGLE_API_KEY ç’°å¢ƒè®Šæ•¸")
    print("è«‹åŸ·è¡Œï¼š$env:GOOGLE_API_KEY='your_api_key_here'")

# API ç«¯é»
TWEET_LIST_API = "https://ttmouse.com/api/tweets"
TWEET_DETAIL_API = "https://twitterhot.vercel.app/api/tweet_info"

# API æ¨¡å‹é…ç½®
GEMINI_MODEL = "gemini-1.5-flash"
EMBEDDING_MODEL = "models/text-embedding-004"

# é è¨­è™•ç†æ•¸é‡é™åˆ¶ï¼ˆç¯€çœ API é…é¡ï¼‰
DEFAULT_LIMIT = 10

# Retry è¨­å®š
MAX_RETRIES = 3
RETRY_DELAY = 2  # ç§’


# ============ å·¥å…·å‡½æ•¸ ============

def init_gemini_api():
    """åˆå§‹åŒ– Gemini API"""
    if not GOOGLE_API_KEY:
        raise ValueError("âŒ GOOGLE_API_KEY æœªè¨­å®šï¼Œç„¡æ³•åˆå§‹åŒ– Gemini API")
    genai.configure(api_key=GOOGLE_API_KEY)
    print("âœ… Gemini API åˆå§‹åŒ–æˆåŠŸ")


def retry_on_failure(func, *args, max_retries=MAX_RETRIES, **kwargs):
    """é€šç”¨ retry è£é£¾å™¨"""
    for attempt in range(max_retries):
        try:
            return func(*args, **kwargs)
        except Exception as e:
            if attempt == max_retries - 1:
                raise
            print(f"âš ï¸  å˜—è©¦ {attempt + 1}/{max_retries} å¤±æ•—ï¼š{e}")
            time.sleep(RETRY_DELAY * (attempt + 1))
    return None


# ============ API çˆ¬å–æ¨¡çµ„ ============

def fetch_tweet_list(date_str: str = None) -> List[Dict[str, Any]]:
    """
    æŠ“å– tweet åˆ—è¡¨
    
    Args:
        date_str: æ—¥æœŸå­—ä¸² (YYYY-MM-DD)ï¼Œé è¨­ç‚ºä»Šå¤©
        
    Returns:
        Tweet åˆ—è¡¨
    """
    if not date_str:
        date_str = datetime.now().strftime("%Y-%m-%d")
    
    url = f"{TWEET_LIST_API}?date={date_str}"
    print(f"ğŸŒ æ­£åœ¨æŠ“å– tweet åˆ—è¡¨ï¼š{url}")
    
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        data = response.json()
        tweets = data if isinstance(data, list) else data.get("items", [])
        
        print(f"âœ… æˆåŠŸå–å¾— {len(tweets)} å€‹ tweets")
        return tweets
        
    except requests.RequestException as e:
        print(f"âŒ API è«‹æ±‚å¤±æ•—ï¼š{e}")
        return []
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æå¤±æ•—ï¼š{e}")
        return []


def fetch_tweet_detail(tweet_id: str) -> Optional[Dict[str, Any]]:
    """
    æŠ“å–å–®å€‹ tweet çš„è©³ç´°è³‡è¨Š
    
    Args:
        tweet_id: Tweet ID
        
    Returns:
        Tweet è©³ç´°è³‡è¨Šå­—å…¸
    """
    url = f"{TWEET_DETAIL_API}?id={tweet_id}"
    
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()
        
        return response.json()
        
    except Exception as e:
        print(f"âŒ å–å¾— tweet è©³æƒ…å¤±æ•— (ID: {tweet_id})ï¼š{e}")
        return None


def extract_prompt_from_tweet(tweet_detail: Dict[str, Any]) -> Optional[str]:
    """
    å¾ tweet è©³æƒ…ä¸­æå– AI prompt
    
    å„ªå…ˆé †åºï¼š
    1. media_extended[].altTextï¼ˆæœ€å¸¸è¦‹çš„ prompt ä½ç½®ï¼‰
    2. textï¼ˆä¸»è¦æ–‡å­—ï¼‰
    3. qrt.textï¼ˆå¼•ç”¨æ¨æ–‡ï¼‰
    
    Args:
        tweet_detail: Tweet è©³ç´°è³‡è¨Š
        
    Returns:
        æå–åˆ°çš„ prompt æ–‡å­—
    """
    # å®‰å…¨æª¢æŸ¥
    if not tweet_detail or not isinstance(tweet_detail, dict):
        return None
    
    # ç­–ç•¥ 1: æª¢æŸ¥ media altText
    media_extended = tweet_detail.get("media_extended", [])
    if media_extended:
        for media in media_extended:
            if not isinstance(media, dict):
                continue
            alt_text = media.get("altText", "").strip()
            if alt_text and len(alt_text) > 20:  # è‡³å°‘ 20 å­—å…ƒ
                return alt_text
    
    # ç­–ç•¥ 2: æª¢æŸ¥ä¸»è¦æ–‡å­—
    text = tweet_detail.get("text", "").strip()
    if text and len(text) > 20:
        return text
    
    # ç­–ç•¥ 3: æª¢æŸ¥å¼•ç”¨æ¨æ–‡
    qrt = tweet_detail.get("qrt")
    if qrt and isinstance(qrt, dict):
        qrt_text = qrt.get("text", "").strip()
        if qrt_text and len(qrt_text) > 20:
            return qrt_text
    
    return None


# ============ Gemini API è½‰æ›æ¨¡çµ„ ============

def transform_prompt_with_gemini(prompt_text: str) -> Optional[Dict[str, Any]]:
    """
    ä½¿ç”¨ Gemini API é€²è¡Œ prompt è½‰æ›ï¼šç¿»è­¯ã€æ¨™ç±¤æå–ã€æ¸…ç†
    
    Args:
        prompt_text: åŸå§‹ prompt æ–‡å­—
        
    Returns:
        åŒ…å« translated_text_zh, tags, cleaned_text çš„å­—å…¸
    """
    try:
        model = genai.GenerativeModel(GEMINI_MODEL)
        
        # å»ºç«‹çµæ§‹åŒ– prompt
        system_prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ AI è—è¡“ prompt åˆ†æå°ˆå®¶ã€‚
è«‹åˆ†æä»¥ä¸‹ AI è—è¡“ç”Ÿæˆ promptï¼Œä¸¦ä»¥ JSON æ ¼å¼å›å‚³ï¼š

{{
  "translated_text_zh": "ç¹é«”ä¸­æ–‡ç¿»è­¯ï¼ˆå°ç£ç”¨èªé¢¨æ ¼ï¼‰",
  "tags": ["æ¨™ç±¤1", "æ¨™ç±¤2", "æ¨™ç±¤3", "æ¨™ç±¤4", "æ¨™ç±¤5"],
  "cleaned_text": "å„ªåŒ–å¾Œçš„è‹±æ–‡ promptï¼ˆç§»é™¤å†—é¤˜è©ã€ä¿®æ­£æ–‡æ³•ï¼‰"
}}

**è¦æ±‚ï¼š**
1. ç¿»è­¯å¿…é ˆç¬¦åˆå°ç£ç¹é«”ä¸­æ–‡ç¿’æ…£ç”¨èª
2. æå– 5 å€‹æœ€èƒ½ä»£è¡¨æ­¤ prompt é¢¨æ ¼çš„æ¨™ç±¤ï¼ˆå¦‚ cyberpunk, watercolor, portrait ç­‰ï¼‰
3. æ¸…ç†å¾Œçš„è‹±æ–‡æ‡‰ä¿æŒåŸæ„ä½†æ›´ç²¾ç°¡å°ˆæ¥­
4. **åƒ…å›å‚³ JSONï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–èªªæ˜æ–‡å­—**

åŸå§‹ Promptï¼š
{prompt_text}
"""
        
        response = model.generate_content(
            system_prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.3,
                candidate_count=1,
            )
        )
        
        # è§£æ JSON å›æ‡‰
        response_text = response.text.strip()
        
        # ç§»é™¤å¯èƒ½çš„ markdown code block æ¨™è¨˜
        if response_text.startswith("```json"):
            response_text = response_text[7:]
        if response_text.startswith("```"):
            response_text = response_text[3:]
        if response_text.endswith("```"):
            response_text = response_text[:-3]
        
        result = json.loads(response_text.strip())
        
        # é©—è­‰å¿…è¦æ¬„ä½
        required_fields = ["translated_text_zh", "tags", "cleaned_text"]
        if not all(field in result for field in required_fields):
            raise ValueError(f"API å›æ‡‰ç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{required_fields}")
        
        return result
        
    except Exception as e:
        print(f"âŒ Gemini API è½‰æ›å¤±æ•—ï¼š{e}")
        return None


def generate_embedding(text: str) -> Optional[List[float]]:
    """
    ä½¿ç”¨ text-embedding-004 ç”Ÿæˆå‘é‡åµŒå…¥
    
    Args:
        text: è¦åµŒå…¥çš„æ–‡å­—
        
    Returns:
        å‘é‡åˆ—è¡¨ï¼ˆ768 ç¶­ï¼‰ï¼Œå¤±æ•—æ™‚è¿”å› None
    """
    try:
        result = genai.embed_content(
            model=EMBEDDING_MODEL,
            content=text,
            task_type="retrieval_document"
        )
        
        embedding = result["embedding"]
        print(f"âœ… ç”Ÿæˆå‘é‡åµŒå…¥ï¼ˆ{len(embedding)} ç¶­ï¼‰")
        return embedding
        
    except Exception as e:
        print(f"âŒ å‘é‡åµŒå…¥ç”Ÿæˆå¤±æ•—ï¼š{e}")
        return None


# ============ ä¸»æµç¨‹ ============

def main(limit: int = DEFAULT_LIMIT, date_str: str = None, test_mode: str = None):
    """
    ä¸» ETL æµç¨‹
    
    Args:
        limit: è™•ç†çš„ prompt æ•¸é‡ä¸Šé™
        date_str: ç›®æ¨™æ—¥æœŸ (YYYY-MM-DD)
        test_mode: æ¸¬è©¦æ¨¡å¼ï¼ˆ"api" æˆ– Noneï¼‰
    """
    print("=" * 60)
    print("ğŸš€ TwitterHot AI Prompt ETL Pipeline")
    print("=" * 60)
    
    # åˆå§‹åŒ– API
    try:
        init_gemini_api()
    except ValueError as e:
        if test_mode != "scrape":
            print(e)
            if test_mode == "api":
                return
    
    # æ¸¬è©¦æ¨¡å¼ï¼šåƒ…æ¸¬è©¦ API
    if test_mode == "api":
        test_prompt = "A beautiful sunset over the ocean, vibrant colors, photorealistic"
        print(f"\nğŸ§ª æ¸¬è©¦ Gemini APIï¼ˆæ¸¬è©¦ promptï¼‰")
        result = transform_prompt_with_gemini(test_prompt)
        if result:
            print("âœ… API æ¸¬è©¦æˆåŠŸ")
            print(json.dumps(result, ensure_ascii=False, indent=2))
        embedding = generate_embedding(test_prompt)
        if embedding:
            print(f"âœ… å‘é‡åµŒå…¥æ¸¬è©¦æˆåŠŸï¼ˆ{len(embedding)} ç¶­ï¼‰")
        return
    
    # å®Œæ•´ ETL æµç¨‹
    if not date_str:
        date_str = datetime.now().strftime("%Y-%m-%d")
    
    print(f"\nğŸ“Š é–‹å§‹è™•ç†ï¼ˆæ—¥æœŸï¼š{date_str}ï¼Œé™åˆ¶ï¼š{limit} å€‹ promptsï¼‰")
    
    # Step 1: æŠ“å– tweet åˆ—è¡¨
    tweets = retry_on_failure(fetch_tweet_list, date_str)
    if not tweets:
        print("âŒ ETL ä¸­æ­¢ï¼šæœªæ‰¾åˆ°ä»»ä½• tweets")
        return
    
    # é™åˆ¶è™•ç†æ•¸é‡
    tweets = tweets[:limit]
    
    # Step 2: è™•ç†æ¯å€‹ tweet
    processed_data = []
    for idx, tweet_meta in enumerate(tweets, 1):
        tweet_id = tweet_meta.get("id")
        if not tweet_id:
            print(f"âš ï¸  è·³éç„¡æ•ˆé …ç›®ï¼ˆç¼ºå°‘ IDï¼‰")
            continue
        
        print(f"\n[{idx}/{len(tweets)}] è™•ç† Tweet ID: {tweet_id}")
        
        # å–å¾—è©³ç´°è³‡è¨Š
        tweet_detail = retry_on_failure(fetch_tweet_detail, tweet_id)
        if not tweet_detail:
            print(f"âš ï¸  è·³éæ­¤ tweetï¼ˆç„¡æ³•å–å¾—è©³æƒ…ï¼‰")
            continue
        
        # æå– prompt
        prompt_text = extract_prompt_from_tweet(tweet_detail)
        if not prompt_text:
            print(f"âš ï¸  è·³éæ­¤ tweetï¼ˆæœªæ‰¾åˆ° prompt æ–‡å­—ï¼‰")
            continue
        
        print(f"åŸæ–‡ï¼š{prompt_text[:80]}...")
        
        # ä½¿ç”¨ Gemini é€²è¡Œè½‰æ›
        transformed = retry_on_failure(
            transform_prompt_with_gemini,
            prompt_text
        )
        
        if not transformed:
            print(f"âš ï¸  è·³éæ­¤ promptï¼ˆè½‰æ›å¤±æ•—ï¼‰")
            continue
        
        # ç”Ÿæˆå‘é‡åµŒå…¥
        embedding = retry_on_failure(
            generate_embedding,
            prompt_text
        )
        
        # çµ„è£æœ€çµ‚æ•¸æ“š
        processed_item = {
            "id": tweet_id,
            "original_prompt": prompt_text,
            "translated_prompt_zh": transformed["translated_text_zh"],
            "cleaned_prompt": transformed["cleaned_text"],
            "tags": transformed["tags"],
            "api_tags": tweet_meta.get("flat_tags", []),  # ä¾†è‡ª API çš„æ¨™ç±¤
            "embedding": embedding or [],
            "author": tweet_meta.get("author", {}),
            "publish_date": tweet_meta.get("publish_date", ""),
            "processed_at": datetime.now().isoformat()
        }
        
        processed_data.append(processed_item)
        print(f"âœ… è™•ç†å®Œæˆï¼š{transformed['translated_text_zh'][:50]}...")
        
        # é¿å… API é€Ÿç‡é™åˆ¶
        time.sleep(0.5)
    
    # Step 3: è¼¸å‡º JSON
    output_filename = f"twitterhot_prompts_{date_str.replace('-', '')}.json"
    output_path = os.path.join(
        os.path.dirname(__file__),
        output_filename
    )
    
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(processed_data, f, ensure_ascii=False, indent=2)
    
    print("\n" + "=" * 60)
    print(f"âœ… ETL å®Œæˆï¼è™•ç†äº† {len(processed_data)}/{len(tweets)} å€‹ prompts")
    print(f"ğŸ“ è¼¸å‡ºæª”æ¡ˆï¼š{output_path}")
    print("=" * 60)


# ============ CLI å…¥å£ ============

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="TwitterHot AI Prompt ETL Pipeline"
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=DEFAULT_LIMIT,
        help=f"è™•ç†çš„ prompt æ•¸é‡ä¸Šé™ï¼ˆé è¨­ï¼š{DEFAULT_LIMIT}ï¼‰"
    )
    parser.add_argument(
        "--date",
        type=str,
        default=None,
        help="ç›®æ¨™æ—¥æœŸ (YYYY-MM-DD)ï¼Œé è¨­ç‚ºä»Šå¤©"
    )
    parser.add_argument(
        "--test-api",
        action="store_true",
        help="åƒ…æ¸¬è©¦ Gemini API é€£ç·š"
    )
    
    args = parser.parse_args()
    
    # æ±ºå®šæ¸¬è©¦æ¨¡å¼
    test_mode = "api" if args.test_api else None
    
    main(limit=args.limit, date_str=args.date, test_mode=test_mode)
